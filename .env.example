# CourtListener MCP Server Environment Configuration
# Copy this file to .env and fill in your actual values

# CourtListener API Configuration
# Get your API key from: https://www.courtlistener.com/api/
COURTLISTENER_API_TOKEN=your_courtlistener_api_token_here

# Server Configuration
NODE_ENV=production

# Ollama Configuration - Built around Ollama (cloud integrations coming soon)
# Default: http://localhost:11434 (local Ollama installation)
# Docker: http://ollama:11434 (if Ollama runs in Docker with service name 'ollama')
# Custom: http://your-ollama-host:11434
OLLAMA_HOST=http://localhost:11434

# Ollama Model Configuration
# Production/Demo model with good function calling support
OLLAMA_MODEL=qwen2.5:7b
# Alternative smaller model for resource-constrained environments
# OLLAMA_MODEL=llama3.2:3b
# Test model (can be different for faster testing)
OLLAMA_MODEL_TEST=qwen2.5:7b

# Security Configuration
# Maximum requests per minute per client
RATE_LIMIT_REQUESTS=100
RATE_LIMIT_WINDOW_MS=60000

# Request timeout in milliseconds
REQUEST_TIMEOUT_MS=30000

# Development Configuration (only for development)
# DEBUG=true
# LOG_LEVEL=debug

# Optional: Custom User Agent
# USER_AGENT=MyApp-CourtListener-MCP/1.0

# Example API token format (40 character hexadecimal string):
# COURTLISTENER_API_TOKEN=a1b2c3d4e5f6789012345678901234567890abcd
