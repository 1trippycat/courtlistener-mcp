version: '3.8'

services:
  # CourtListener MCP Server - Standalone
  courtlistener-mcp:
    image: ghcr.io/1trippycat/courtlistener-mcp:latest
    container_name: courtlistener-mcp
    environment:
      - COURTLISTENER_API_TOKEN=${COURTLISTENER_API_TOKEN}
      - NODE_ENV=production
      - RATE_LIMIT_REQUESTS=100
      - RATE_LIMIT_WINDOW_MS=60000
      - REQUEST_TIMEOUT_MS=30000
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "node", "-e", "console.log('healthy')"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - mcp-network

  # Optional: Open WebUI for AI chat interface with MCP integration
  open-webui:
    image: ghcr.io/open-webui/open-webui:main
    container_name: open-webui
    ports:
      - "3000:8080"
    volumes:
      - open-webui-data:/app/backend/data
    environment:
      - 'MCP_SERVERS={"courtlistener": {"command": "docker", "args": ["exec", "courtlistener-mcp", "node", "/app/build/index.js"]}}'
    depends_on:
      courtlistener-mcp:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - mcp-network

  # Example: Add to your existing services
  # your-existing-service:
  #   image: your-app:latest
  #   environment:
  #     - MCP_SERVER_HOST=courtlistener-mcp
  #   depends_on:
  #     - courtlistener-mcp
  #   networks:
  #     - mcp-network

volumes:
  open-webui-data:
    driver: local

networks:
  mcp-network:
    driver: bridge
